{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refs**\n",
    "https://github.com/bikz05/ipython-notebooks/blob/master/computer-vision/displaying-video-in-ipython-notebook.ipynb\n",
    "\n",
    "**PyImageSearch Transfer Learning Tutorial**\n",
    "    https://www.pyimagesearch.com/2019/05/20/transfer-learning-with-keras-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# one-time prep work\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# set matplotlib to render in this window, with the specified figure size\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "#pylab.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%pylab inline \n",
    "pylab.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import scipy.ndimage as sciimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video/Data Paths\n",
    "\n",
    "nonePath = 'Videos/Data/None/None_true.mp4'\n",
    "itemPath = 'Videos/Data/Tear/Tear_Ww.mp4'\n",
    "\n",
    "pixstep = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGridLines(frame, line_color=(0, 255, 0), thickness=1, type_=cv2.LINE_AA, pxstep=100):\n",
    "    x = pxstep\n",
    "    y = pxstep\n",
    "    while x < frame.shape[1]:\n",
    "        cv2.line(frame, (x, 0), (x, frame.shape[0]), color=line_color, lineType=type_, thickness=thickness)\n",
    "        x += pxstep\n",
    "    while y < frame.shape[0]:\n",
    "        cv2.line(frame, (0, y), (frame.shape[1], y), color=line_color, lineType=type_, thickness=thickness)\n",
    "        y += pxstep\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBox(frame, xpts = (0, 1), ypts = (0, 1), line_color=(255, 0, 0), thickness = 2, type_=cv2.LINE_AA, pxstep=200):\n",
    "    x1, x2 = xpts\n",
    "    y1, y2 = ypts\n",
    "    \n",
    "    x1*=pxstep\n",
    "    x2*=pxstep\n",
    "    y1*=pxstep\n",
    "    y2*=pxstep\n",
    "    \n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), line_color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "#drawBox(frame, (1, 2), (3, 4),  pxstep=200)\n",
    "#pxstep = 200\n",
    "#frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "print(frame.shape)\n",
    "def cropFrame(frame, xpts=(x1, x2), ypts=(y1, y2), pxstep=200):\n",
    "    plt.imshow(frame[3*pxstep:4*pxstep, 1*pxstep:2*pxstep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoToFrameLabel(vidpath, outDir='train_images/', cropped = False, xpts = (1, 2), ypts = (3, 4), pxstep=200):\n",
    "    #Read Video Frame By Frame\n",
    "    vid = cv2.VideoCapture(vidpath)\n",
    "    top = y1*pxstep\n",
    "    bot = y2*pxstep\n",
    "    left = x1*pxstep\n",
    "    right = x2*pxstep\n",
    "    #plt.imshow(game[top:bot, left:right])\n",
    "\n",
    "    # Put the code in try-except statements\n",
    "    # Catch the keyboard exception and \n",
    "    # release the camera device and \n",
    "    # continue with the rest of code.\n",
    "    try:\n",
    "        frame_no = 0\n",
    "        prefix = outDir + vidpath.split('/')[-1].split('.')[0]\n",
    "        print(\"[INFO] Writing to \"+outDir+\" ...\")\n",
    "        while(True):\n",
    "            frame_no+=1 \n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = vid.read()\n",
    "            if not ret:\n",
    "                # Release the Video Device if ret is false\n",
    "                vid.release()\n",
    "                # Message to be displayed after releasing the device\n",
    "                print(\"Released Video Resource\")\n",
    "                break\n",
    "            # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "            # to display the image\n",
    "            #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            outPath = prefix + '-' + str(frame_no) +'.png'\n",
    "            if cropped == True: \n",
    "                cv2.imwrite(outPath, frame[top:bot, left:right])\n",
    "            else: \n",
    "                cv2.imwrite(outPath, frame)\n",
    "\n",
    "        print(\"[INFO] Done writing\")\n",
    "    except KeyboardInterrupt:\n",
    "        # Release the Video Device\n",
    "        vid.release()\n",
    "        # Message to be displayed after releasing the device\n",
    "        print(\"[Detected Interupt]: Stopped writing at frame \" + str(frame) + \", released video resource\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing to validation_images/tear/ ...\n",
      "Released Video Resource\n",
      "[INFO] Done writing\n"
     ]
    }
   ],
   "source": [
    "itemPath = 'Videos/Data/Tear/Tear_enemy.mp4'\n",
    "#itemPath = 'Videos/Data/None/None_Varus.mp4'\n",
    "#videoToFrameLabel(itemPath, outDir='train_images/none/', cropped = True)\n",
    "videoToFrameLabel(itemPath, outDir='validation_images/tear/', cropped = False)\n",
    "\n",
    "#videoToFrameLabel(itemPath, outDir='train_images/tear/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "#Read Video Frame By Frame\n",
    "vidpath = itemPath\n",
    "# You can also give path to the video file\n",
    "#itemPath = 'Videos/Data/Tear/Tear_Kha.mp4'\n",
    "itemPath = 'Videos/Data/None/None_belt_shiv.mp4'\n",
    "vid = cv2.VideoCapture(vidpath)\n",
    "x1, x2, y1, y2 = (1, 2, 3, 4)\n",
    "pxstep=200\n",
    "top = y1*pxstep\n",
    "bot = y2*pxstep\n",
    "left = x1*pxstep\n",
    "right = x2*pxstep\n",
    "\n",
    "# Put the code in try-except statements\n",
    "# Catch the keyboard exception and \n",
    "# release the camera device and \n",
    "# continue with the rest of code.\n",
    "try:\n",
    "    frame_no = 0\n",
    "    prefix = vidpath.split('/')[-1].split('.')[0]\n",
    "    while(True):\n",
    "        frame_no+=1 \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Message to be displayed after releasing the device\n",
    "            print(\"Released Video Resource\")\n",
    "            break\n",
    "        # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "        # to display the image\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        drawGridLines(frame, pxstep=200)\n",
    "        # Turn off the axis\n",
    "        # Title of the window\n",
    "        title(\"Input Stream Frame_No: \"+str(frame_no))\n",
    "        # Display the frame\n",
    "        imshow(frame[top:bot, left:right])\n",
    "        show()\n",
    "        # Display the frame until new frame is available\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print(\"Released Video Resource\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
